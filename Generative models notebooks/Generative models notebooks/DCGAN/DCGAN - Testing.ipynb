{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testDCGAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzffyhsatwzI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9a7e7d59-b860-49f4-a5ac-f3cecca48009"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#!zip -F file.zip --out file-large.zip\n",
        "#!unzip file-large.zip\n",
        "#!unzip \"/content/drive/My Drive/img_align_celeba.zip\"\n",
        "!cat '/content/drive/My Drive/utils.py'\n",
        "!cat '/content/drive/My Drive/ops.py'\n",
        "!cat '/content/drive/My Drive/models_64x64.py'\n",
        "import sys\n",
        "import imageio\n",
        "sys.path.append('/content/drive/My Drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "from __future__ import division\n",
            "from __future__ import print_function\n",
            "from __future__ import absolute_import\n",
            "\n",
            "import os\n",
            "import re\n",
            "import scipy\n",
            "import numpy as np\n",
            "import tensorflow as tf\n",
            "import cv2\n",
            "import imageio\n",
            "\n",
            "from collections import OrderedDict\n",
            "\n",
            "\n",
            "def mkdir(paths):\n",
            "    if not isinstance(paths, (list, tuple)):\n",
            "        paths = [paths]\n",
            "    for path in paths:\n",
            "        path_dir, _ = os.path.split(path)\n",
            "        if not os.path.isdir(path_dir):\n",
            "            os.makedirs(path_dir)\n",
            "\n",
            "\n",
            "def session(graph=None, allow_soft_placement=True,\n",
            "            log_device_placement=False, allow_growth=True):\n",
            "    \"\"\" return a Session with simple config \"\"\"\n",
            "\n",
            "    config = tf.ConfigProto(allow_soft_placement=allow_soft_placement,\n",
            "                            log_device_placement=log_device_placement)\n",
            "    config.gpu_options.allow_growth = allow_growth\n",
            "    return tf.Session(graph=graph, config=config)\n",
            "\n",
            "\n",
            "def tensors_filter(tensors, filters, combine_type='or'):\n",
            "    assert isinstance(tensors, (list, tuple)), '`tensors` shoule be a list or tuple!'\n",
            "    assert isinstance(filters, (str, list, tuple)), \\\n",
            "        '`filters` should be a string or a list(tuple) of strings!'\n",
            "    assert combine_type == 'or' or combine_type == 'and', \"`combine_type` should be 'or' or 'and'!\"\n",
            "\n",
            "    if isinstance(filters, str):\n",
            "        filters = [filters]\n",
            "\n",
            "    f_tens = []\n",
            "    for ten in tensors:\n",
            "        if combine_type == 'or':\n",
            "            for filt in filters:\n",
            "                if filt in ten.name:\n",
            "                    f_tens.append(ten)\n",
            "                    break\n",
            "        elif combine_type == 'and':\n",
            "            all_pass = True\n",
            "            for filt in filters:\n",
            "                if filt not in ten.name:\n",
            "                    all_pass = False\n",
            "                    break\n",
            "            if all_pass:\n",
            "                f_tens.append(ten)\n",
            "    return f_tens\n",
            "\n",
            "\n",
            "def trainable_variables(filters=None, combine_type='or'):\n",
            "    t_var = tf.trainable_variables()\n",
            "    if filters is None:\n",
            "        return t_var\n",
            "    else:\n",
            "        return tensors_filter(t_var, filters, combine_type)\n",
            "\n",
            "\n",
            "def summary(tensor_collection, summary_type=['mean', 'stddev', 'max', 'min', 'sparsity', 'histogram']):\n",
            "    \"\"\"\n",
            "    usage:\n",
            "\n",
            "    1. summary(tensor)\n",
            "\n",
            "    2. summary([tensor_a, tensor_b])\n",
            "\n",
            "    3. summary({tensor_a: 'a', tensor_b: 'b})\n",
            "    \"\"\"\n",
            "\n",
            "    def _summary(tensor, name, summary_type=['mean', 'stddev', 'max', 'min', 'sparsity', 'histogram', 'image']):\n",
            "        \"\"\" Attach a lot of summaries to a Tensor. \"\"\"\n",
            "\n",
            "        if name is None:\n",
            "            # Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training\n",
            "            # session. This helps the clarity of presentation on tensorboard.\n",
            "            name = re.sub('%s_[0-9]*/' % 'tower', '', tensor.name)\n",
            "            name = re.sub(':', '-', name)\n",
            "\n",
            "        with tf.name_scope('summary_' + name):\n",
            "            summaries = []\n",
            "            if len(tensor._shape) == 0:\n",
            "                summaries.append(tf.summary.scalar(name, tensor))\n",
            "            else:\n",
            "                if 'mean' in summary_type:\n",
            "                    mean = tf.reduce_mean(tensor)\n",
            "                    summaries.append(tf.summary.scalar(name + '/mean', mean))\n",
            "                if 'stddev' in summary_type:\n",
            "                    mean = tf.reduce_mean(tensor)\n",
            "                    stddev = tf.sqrt(tf.reduce_mean(tf.square(tensor - mean)))\n",
            "                    summaries.append(tf.summary.scalar(name + '/stddev', stddev))\n",
            "                if 'max' in summary_type:\n",
            "                    summaries.append(tf.summary.scalar(name + '/max', tf.reduce_max(tensor)))\n",
            "                if 'min' in summary_type:\n",
            "                    summaries.append(tf.summary.scalar(name + '/min', tf.reduce_min(tensor)))\n",
            "                if 'sparsity' in summary_type:\n",
            "                    summaries.append(tf.summary.scalar(name + '/sparsity', tf.nn.zero_fraction(tensor)))\n",
            "                if 'histogram' in summary_type:\n",
            "                    summaries.append(tf.summary.histogram(name, tensor))\n",
            "                if 'image' in summary_type:\n",
            "                    summaries.append(tf.summary.image(name, tensor))\n",
            "            return tf.summary.merge(summaries)\n",
            "\n",
            "    if not isinstance(tensor_collection, (list, tuple, dict)):\n",
            "        tensor_collection = [tensor_collection]\n",
            "    with tf.name_scope('summaries'):\n",
            "        summaries = []\n",
            "        if isinstance(tensor_collection, (list, tuple)):\n",
            "            for tensor in tensor_collection:\n",
            "                summaries.append(_summary(tensor, None, summary_type))\n",
            "        else:\n",
            "            for tensor, name in tensor_collection.items():\n",
            "                summaries.append(_summary(tensor, name, summary_type))\n",
            "        return tf.summary.merge(summaries)\n",
            "\n",
            "\n",
            "def counter(scope='counter'):\n",
            "    with tf.variable_scope(scope):\n",
            "        counter = tf.Variable(0, dtype=tf.int32, name='counter')\n",
            "        update_cnt = tf.assign(counter, tf.add(counter, 1))\n",
            "        return counter, update_cnt\n",
            "\n",
            "\n",
            "def load_checkpoint(checkpoint_dir, session, var_list=None):\n",
            "    print(' [*] Loading checkpoint...')\n",
            "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
            "    if ckpt and ckpt.model_checkpoint_path:\n",
            "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
            "        ckpt_path = os.path.join(checkpoint_dir, ckpt_name)\n",
            "    try:\n",
            "        restorer = tf.train.Saver(var_list)\n",
            "        restorer.restore(session, ckpt_path)\n",
            "        print(' [*] Loading successful! Copy variables from % s' % ckpt_path)\n",
            "        return True\n",
            "    except:\n",
            "        print(' [*] No suitable checkpoint!')\n",
            "        return False\n",
            "\n",
            "\n",
            "def memory_data_batch(memory_data_dict, batch_size, preprocess_fns={}, shuffle=True, num_threads=16,\n",
            "                      min_after_dequeue=5000, allow_smaller_final_batch=False, scope=None):\n",
            "    \"\"\"\n",
            "    memory_data_dict:\n",
            "        for example\n",
            "        {'img': img_ndarray, 'point': point_ndarray} or\n",
            "        {'img': img_tensor, 'point': point_tensor}\n",
            "        the value of each item of `memory_data_dict` is in shape of (N, ...)\n",
            "\n",
            "    preprocess_fns:\n",
            "        for example\n",
            "        {'img': img_preprocess_fn, 'point': point_preprocess_fn}\n",
            "    \"\"\"\n",
            "\n",
            "    with tf.name_scope(scope, 'memory_data_batch'):\n",
            "        fields = []\n",
            "        tensor_dict = OrderedDict()\n",
            "        for k in memory_data_dict:\n",
            "            fields.append(k)\n",
            "            tensor_dict[k] = tf.convert_to_tensor(memory_data_dict[k])  # the same dtype of the input data\n",
            "        data_num = tensor_dict[k].get_shape().as_list()[0]\n",
            "\n",
            "        # slice to single example, and since it's memory data, the `capacity` is set as data_num\n",
            "        data_values = tf.train.slice_input_producer(list(tensor_dict.values()), shuffle=shuffle, capacity=data_num)\n",
            "        data_keys = list(tensor_dict.keys())\n",
            "        data_dict = {}\n",
            "        for k, v in zip(data_keys, data_values):\n",
            "            if k in preprocess_fns:\n",
            "                data_dict[k] = preprocess_fns[k](v)\n",
            "            else:\n",
            "                data_dict[k] = v\n",
            "\n",
            "        # batch datas\n",
            "        if shuffle:\n",
            "            capacity = min_after_dequeue + (num_threads + 1) * batch_size\n",
            "            data_batch = tf.train.shuffle_batch(data_dict,\n",
            "                                                batch_size=batch_size,\n",
            "                                                capacity=capacity,\n",
            "                                                min_after_dequeue=min_after_dequeue,\n",
            "                                                num_threads=num_threads,\n",
            "                                                allow_smaller_final_batch=allow_smaller_final_batch)\n",
            "        else:\n",
            "            data_batch = tf.train.batch(data_dict,\n",
            "                                        batch_size=batch_size,\n",
            "                                        allow_smaller_final_batch=allow_smaller_final_batch)\n",
            "\n",
            "        return data_batch, data_num, fields\n",
            "\n",
            "\n",
            "class MemoryData:\n",
            "\n",
            "    def __init__(self, memory_data_dict, batch_size, preprocess_fns={}, shuffle=True, num_threads=16,\n",
            "                 min_after_dequeue=5000, allow_smaller_final_batch=False, scope=None):\n",
            "        \"\"\"\n",
            "        memory_data_dict:\n",
            "            for example\n",
            "            {'img': img_ndarray, 'point': point_ndarray} or\n",
            "            {'img': img_tensor, 'point': point_tensor}\n",
            "            the value of each item of `memory_data_dict` is in shape of (N, ...)\n",
            "\n",
            "        preprocess_fns:\n",
            "            for example\n",
            "            {'img': img_preprocess_fn, 'point': point_preprocess_fn}\n",
            "        \"\"\"\n",
            "\n",
            "        self.graph = tf.Graph()  # declare ops in a separated graph\n",
            "        with self.graph.as_default():\n",
            "            self._batch_ops, self._data_num, self._fields = memory_data_batch(memory_data_dict, batch_size,\n",
            "                                                                              preprocess_fns, shuffle, num_threads,\n",
            "                                                                              min_after_dequeue,\n",
            "                                                                              allow_smaller_final_batch, scope)\n",
            "\n",
            "        print(' [*] MemoryData: create session!')\n",
            "        self.sess = session(graph=self.graph)\n",
            "        self.coord = tf.train.Coordinator()\n",
            "        self.threads = tf.train.start_queue_runners(sess=self.sess, coord=self.coord)\n",
            "\n",
            "    def __len__(self):\n",
            "        return self._data_num\n",
            "\n",
            "    def batch(self, fields=None):\n",
            "\n",
            "        batch_data = self.sess.run(self._batch_ops)\n",
            "        if fields is None:\n",
            "            fields = self._fields\n",
            "        if isinstance(fields, (list, tuple)):\n",
            "            return [batch_data[field] for field in fields]\n",
            "        else:\n",
            "            return batch_data[fields]\n",
            "\n",
            "    def fields(self):\n",
            "        return self._fields\n",
            "\n",
            "    def __del__(self):\n",
            "        print(' [*] MemoryData: stop threads and close session!')\n",
            "        self.coord.request_stop()\n",
            "        self.coord.join(self.threads)\n",
            "        self.sess.close()\n",
            "\n",
            "\n",
            "def read_labeled_image_list(image_list_file):\n",
            "    mydir = os.listdir(image_list_file)\n",
            "    filenames = []\n",
            "    for filename in mydir:\n",
            "        filename = image_list_file + filename\n",
            "        filenames.append(filename)\n",
            "\n",
            "    return filenames\n",
            "\n",
            "\n",
            "def read_labeled_image_list_4_ilsvrc(image_list_file):\n",
            "    mydir = os.listdir(image_list_file)\n",
            "    filenames = []\n",
            "    for filename in mydir:\n",
            "        f = image_list_file + filename\n",
            "        filenames.append(f)\n",
            "    return filenames\n",
            "\n",
            "\n",
            "def disk_image_batch(image_paths, batch_size, shape, preprocess_fn=None, shuffle=True, num_threads=16,\n",
            "                     min_after_dequeue=100, allow_smaller_final_batch=False, scope=None):\n",
            "    \"\"\"\n",
            "    This function is suitable for bmp, jpg, png and gif files\n",
            "\n",
            "    image_paths: string list or 1-D tensor, each of which is an iamge path\n",
            "    preprocess_fn: single image preprocessing function\n",
            "    \"\"\"\n",
            "\n",
            "    with tf.name_scope(scope, 'disk_image_batch'):\n",
            "        # batch datas\n",
            "        #         image_list = read_labeled_image_list(image_paths)\n",
            "        image_list = read_labeled_image_list_4_ilsvrc(image_paths)\n",
            "        data_num = len(image_list)\n",
            "        print(\"#Data is \", data_num)\n",
            "        image_list = tf.cast(image_list, tf.string)\n",
            "\n",
            "        input_queue = tf.train.slice_input_producer([image_list], shuffle=shuffle)\n",
            "        file_contents = tf.read_file(input_queue[0])\n",
            "        image = tf.image.decode_jpeg(file_contents, channels=3)\n",
            "        image = tf.image.resize_images(image, [shape[0], shape[1]])\n",
            "\n",
            "        channels = 3\n",
            "        image.set_shape(shape)\n",
            "\n",
            "        # Crop and other random augmentations\n",
            "        if shuffle is False:\n",
            "            image = tf.image.random_flip_left_right(image)\n",
            "            image = tf.image.random_saturation(image, .95, 1.05)\n",
            "            image = tf.image.random_brightness(image, .05)\n",
            "            image = tf.image.random_contrast(image, .95, 1.05)\n",
            "        crop_size = 108\n",
            "        re_size = 64\n",
            "        #         image = tf.image.crop_to_bounding_box(image, 65, 35, 108, 108)\n",
            "        image = tf.to_float(\n",
            "            tf.image.resize_images(image, [re_size, re_size], method=tf.image.ResizeMethod.BICUBIC)) / 127.5 - 1\n",
            "        image = tf.cast(image, tf.float32)\n",
            "\n",
            "        img_batch = tf.train.batch([image], batch_size=batch_size, capacity=32, name='images')\n",
            "\n",
            "        return img_batch, data_num\n",
            "\n",
            "\n",
            "class DiskImageData:\n",
            "\n",
            "    def __init__(self, image_paths, batch_size, shape, preprocess_fn=None, shuffle=True, num_threads=16,\n",
            "                 min_after_dequeue=100, allow_smaller_final_batch=False, scope=None):\n",
            "        \"\"\"\n",
            "        This function is suitable for bmp, jpg, png and gif files\n",
            "\n",
            "        image_paths: string list or 1-D tensor, each of which is an iamge path\n",
            "        preprocess_fn: single image preprocessing function\n",
            "        \"\"\"\n",
            "\n",
            "        self.graph = tf.Graph()  # declare ops in a separated graph\n",
            "        with self.graph.as_default():\n",
            "            self._batch_ops, self._data_num = disk_image_batch(image_paths, batch_size, shape, preprocess_fn, shuffle,\n",
            "                                                               num_threads,\n",
            "                                                               min_after_dequeue, allow_smaller_final_batch, scope)\n",
            "\n",
            "        print(' [*] DiskImageData: create session!')\n",
            "        self.sess = session(graph=self.graph)\n",
            "        self.coord = tf.train.Coordinator()\n",
            "        self.threads = tf.train.start_queue_runners(sess=self.sess, coord=self.coord)\n",
            "\n",
            "    def __len__(self):\n",
            "        return self._data_num\n",
            "\n",
            "    def batch(self):\n",
            "        return self.sess.run(self._batch_ops)\n",
            "\n",
            "    def __del__(self):\n",
            "        print(' [*] DiskImageData: stop threads and close session!')\n",
            "        self.coord.request_stop()\n",
            "        self.coord.join(self.threads)\n",
            "        self.sess.close()\n",
            "\n",
            "\n",
            "def to_range(images, min_value=0.0, max_value=1.0, dtype=None):\n",
            "    \"\"\"\n",
            "    transform images from [-1.0, 1.0] to [min_value, max_value] of dtype\n",
            "    \"\"\"\n",
            "    assert \\\n",
            "        np.min(images) >= -1.0 - 1e-5 and np.max(images) <= 1.0 + 1e-5 \\\n",
            "        and (images.dtype == np.float32 or images.dtype == np.float64), \\\n",
            "        'The input images should be float64(32) and in the range of [-1.0, 1.0]!'\n",
            "    if dtype is None:\n",
            "        dtype = images.dtype\n",
            "    return ((images + 1.) / 2. * (max_value - min_value) + min_value).astype(dtype)\n",
            "\n",
            "\n",
            "def to_range(images):\n",
            "    maxval = np.max(images)\n",
            "    minval = np.min(images)\n",
            "    return np.asarray((images - minval) / (maxval - minval) * 255, np.uint8)\n",
            "\n",
            "\n",
            "def imwrite(image, path):\n",
            "    \"\"\" save an [-1.0, 1.0] image \"\"\"\n",
            "\n",
            "    if image.ndim == 3 and image.shape[2] == 1:  # for gray image\n",
            "        image = np.array(image, copy=True)\n",
            "        image.shape = image.shape[0:2]\n",
            "    return imageio.imwrite(path, image)\n",
            "\n",
            "\n",
            "def batchimwrite2(image, path):\n",
            "    \"\"\" save an [-1.0, 1.0] image \"\"\"\n",
            "\n",
            "    for i in range(image.shape[0]):\n",
            "        image = np.array(image, copy=True)\n",
            "        scipy.misc.imsave(\"%s%d.jpg\" % (path, i), to_range(image[i, :, :, 0]))\n",
            "\n",
            "\n",
            "def batchsalwrite(image, sal, tis, vis, path):\n",
            "    \"\"\" save an [-1.0, 1.0] image \"\"\"\n",
            "\n",
            "    image = np.array(image, copy=True)\n",
            "    sal = np.array(sal, copy=True)\n",
            "    for i in range(image.shape[0]):\n",
            "        im1 = np.asarray(to_range(image[i, :, :, :]), np.float)\n",
            "        scipy.misc.imsave(\"%s_Original_%d_%d-%d.jpg\" % (path, i, tis[i], vis[i]), np.asarray(im1, np.uint8))\n",
            "        sal1 = np.asarray(sal[i, :, :], np.float) * 255\n",
            "        sal1 = np.expand_dims(sal1, 2)\n",
            "        sal1 = cv2.resize(sal1, (64, 64))\n",
            "        sal1 = np.reshape(sal1, [64, 64])\n",
            "        scipy.misc.imsave(\"%s_Saliency_%d_%d-%d.jpg\" % (path, i, tis[i], vis[i]), np.asarray(sal1, np.uint8))\n",
            "\n",
            "        im1[:, :, 0] = im1[:, :, 0] + sal1 * 0.4\n",
            "        im1[:, :, 1] = (im1[:, :, 1] - sal1 * 0.2)\n",
            "        im1[:, :, 2] = (im1[:, :, 2] - sal1 * 0.2)\n",
            "        im1[im1 > 255] = 255\n",
            "        im1[im1 < 0] = 0\n",
            "        im1 = np.asarray(im1, np.uint8)\n",
            "        scipy.misc.imsave(\"%s%d_%d-%d.jpg\" % (path, i, tis[i], vis[i]), im1)\n",
            "\n",
            "\n",
            "def batchimwrite3(image, path):\n",
            "    \"\"\" save an [-1.0, 1.0] image \"\"\"\n",
            "\n",
            "    for i in range(image.shape[0]):\n",
            "        image = np.array(image, copy=True)\n",
            "        scipy.misc.imsave(\"%s%d.jpg\" % (path, i), to_range(image[i, :, :, :]))\n",
            "\n",
            "\n",
            "def batchimwrite(image, path):\n",
            "    \"\"\" save an [-1.0, 1.0] image \"\"\"\n",
            "\n",
            "    for i in range(image.shape[0]):\n",
            "        image = np.array(image, copy=True)\n",
            "        scipy.misc.imsave(\"%s%d.jpg\" % (path, i), to_range(image[i, :, :, :], 0, 255, np.uint8))\n",
            "\n",
            "\n",
            "def immerge(images, row, col):\n",
            "    \"\"\"\n",
            "    merge images into an image with (row * h) * (col * w)\n",
            "\n",
            "    `images` is in shape of N * H * W(* C=1 or 3)\n",
            "    \"\"\"\n",
            "\n",
            "    h, w = images.shape[1], images.shape[2]\n",
            "    if images.ndim == 4:\n",
            "        img = np.zeros((h * row, w * col, images.shape[3]))\n",
            "    elif images.ndim == 3:\n",
            "        img = np.zeros((h * row, w * col))\n",
            "    for idx, image in enumerate(images):\n",
            "        i = idx % col\n",
            "        j = idx // col\n",
            "        img[j * h:j * h + h, i * w:i * w + w, ...] = image\n",
            "\n",
            "    return img\n",
            "from __future__ import absolute_import\n",
            "from __future__ import division\n",
            "from __future__ import print_function\n",
            "\n",
            "import tensorflow as tf\n",
            "import tensorflow.contrib.slim as slim\n",
            "\n",
            "\n",
            "def flatten_fully_connected(inputs,\n",
            "                            num_outputs,\n",
            "                            activation_fn=tf.nn.relu,\n",
            "                            normalizer_fn=None,\n",
            "                            normalizer_params=None,\n",
            "                            weights_initializer=slim.xavier_initializer(),\n",
            "                            weights_regularizer=None,\n",
            "                            biases_initializer=tf.zeros_initializer(),\n",
            "                            biases_regularizer=None,\n",
            "                            reuse=None,\n",
            "                            variables_collections=None,\n",
            "                            outputs_collections=None,\n",
            "                            trainable=True,\n",
            "                            scope=None):\n",
            "    with tf.variable_scope(scope, 'flatten_fully_connected', [inputs]):\n",
            "        if inputs.shape.ndims > 2:\n",
            "            inputs = slim.flatten(inputs)\n",
            "        return slim.fully_connected(inputs,\n",
            "                                    num_outputs,\n",
            "                                    activation_fn,\n",
            "                                    normalizer_fn,\n",
            "                                    normalizer_params,\n",
            "                                    weights_initializer,\n",
            "                                    weights_regularizer,\n",
            "                                    biases_initializer,\n",
            "                                    biases_regularizer,\n",
            "                                    reuse,\n",
            "                                    variables_collections,\n",
            "                                    outputs_collections,\n",
            "                                    trainable,\n",
            "                                    scope)\n",
            "\n",
            "\n",
            "def leak_relu(x, leak, scope=None):\n",
            "    with tf.name_scope(scope, 'leak_relu', [x, leak]):\n",
            "        if leak < 1:\n",
            "            y = tf.maximum(x, leak * x)\n",
            "        else:\n",
            "            y = tf.minimum(x, leak * x)\n",
            "        return y\n",
            "from __future__ import division\n",
            "from __future__ import print_function\n",
            "from __future__ import absolute_import\n",
            "\n",
            "import ops\n",
            "import tensorflow as tf\n",
            "import tensorflow.contrib.slim as slim\n",
            "\n",
            "from functools import partial\n",
            "\n",
            "conv = partial(slim.conv2d, activation_fn=None, weights_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
            "dconv = partial(slim.conv2d_transpose, activation_fn=None, weights_initializer=tf.random_normal_initializer(stddev=0.02))\n",
            "fc = partial(ops.flatten_fully_connected, activation_fn=None, weights_initializer=tf.random_normal_initializer(stddev=0.02))\n",
            "relu = tf.nn.relu\n",
            "lrelu = partial(ops.leak_relu, leak=0.2)\n",
            "batch_norm = partial(slim.batch_norm, decay=0.9, scale=True, epsilon=1e-5, updates_collections=None)\n",
            "ln = slim.layer_norm\n",
            "\n",
            "\n",
            "def generator(z, dim=64, reuse=True, training=True):\n",
            "    bn = partial(batch_norm, is_training=training)\n",
            "    dconv_bn_relu = partial(dconv, normalizer_fn=bn, activation_fn=relu, biases_initializer=None)\n",
            "    fc_bn_relu = partial(fc, normalizer_fn=bn, activation_fn=relu, biases_initializer=None)\n",
            "\n",
            "    with tf.variable_scope('generator', reuse=reuse):\n",
            "        y = fc_bn_relu(z, 4 * 4 * dim * 8)\n",
            "        y = tf.reshape(y, [-1, 4, 4, dim * 8])\n",
            "        y = dconv_bn_relu(y, dim * 4, 5, 2)\n",
            "        y = dconv_bn_relu(y, dim * 2, 5, 2)\n",
            "        y = dconv_bn_relu(y, dim * 1, 5, 2)\n",
            "        img = tf.tanh(dconv(y, 3, 5, 2))\n",
            "        return img\n",
            "\n",
            "\n",
            "def discriminator(img, dim=64, reuse=True, training=True):\n",
            "    bn = partial(batch_norm, is_training=training)\n",
            "    conv_bn_lrelu = partial(conv, normalizer_fn=bn, activation_fn=lrelu, biases_initializer=None)\n",
            "\n",
            "    with tf.variable_scope('discriminator', reuse=reuse):\n",
            "        y = lrelu(conv(img, dim, 5, 2))\n",
            "        y = conv_bn_lrelu(y, dim * 2, 5, 2)\n",
            "        y = conv_bn_lrelu(y, dim * 4, 5, 2)\n",
            "        y = conv_bn_lrelu(y, dim * 8, 5, 2)\n",
            "        logit = fc(y, 1)\n",
            "        return logit\n",
            "\n",
            "\n",
            "def discriminator_wgan_gp(img, dim=64, reuse=True, training=True):\n",
            "    conv_ln_lrelu = partial(conv, normalizer_fn=ln, activation_fn=lrelu, biases_initializer=None)\n",
            "\n",
            "    with tf.variable_scope('discriminator', reuse=reuse):\n",
            "        y = lrelu(conv(img, dim, 5, 2))\n",
            "        y = conv_ln_lrelu(y, dim * 2, 5, 2)\n",
            "        y = conv_ln_lrelu(y, dim * 4, 5, 2)\n",
            "        y = conv_ln_lrelu(y, dim * 8, 5, 2)\n",
            "        logit = fc(y, 1)\n",
            "        return logit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtsqD-Onupn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "outputId": "7b9e9985-329c-44cd-d86a-f143a6db3543"
      },
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import glob\n",
        "import utils\n",
        "import traceback\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import models_64x64 as models\n",
        "\n",
        "def to_range(images, min_value=0.0, max_value=1.0, dtype=None):\n",
        "    \"\"\"\n",
        "    transform images from [-1.0, 1.0] to [min_value, max_value] of dtype\n",
        "    \"\"\"\n",
        "    assert \\\n",
        "        np.min(images) >= -1.0 - 1e-5 and np.max(images) <= 1.0 + 1e-5 \\\n",
        "        and (images.dtype == np.float32 or images.dtype == np.float64), \\\n",
        "        'The input images should be float64(32) and in the range of [-1.0, 1.0]!'\n",
        "    if dtype is None:\n",
        "        dtype = images.dtype\n",
        "    return ((images + 1.) / 2. * (max_value - min_value) + min_value).astype(dtype)\n",
        "\n",
        "\n",
        "def batchimwrite(image, path, cnt, prob):\n",
        "    \"\"\" save an [-1.0, 1.0] image \"\"\"\n",
        "\n",
        "    for i in range(image.shape[0]):\n",
        "        image = np.array(image, copy=True)\n",
        "\n",
        "        if (prob[i] > -4.5 and cnt < 50) :\n",
        "            imageio.imwrite(\"%s_%d.jpg\" % (path, cnt) , to_range(image[i, :, :, :], 0, 255, np.uint8))\n",
        "            cnt += 1\n",
        "            print(cnt,prob[i])\n",
        "\n",
        "    return cnt\n",
        "\n",
        "\"\"\" param \"\"\"\n",
        "epoch = 50\n",
        "batch_size = 100\n",
        "lr = 0.0002\n",
        "z_dim = 100\n",
        "gpu_id = 3\n",
        "\n",
        "''' data '''\n",
        "# you should prepare your own data in ./data/img_align_celeba\n",
        "# celeba original size is [218, 178, 3]\n",
        "tf.reset_default_graph()\n",
        "\n",
        "\"\"\" graphs \"\"\"\n",
        "with tf.device('/gpu:%d' % gpu_id):\n",
        "    ''' models '''\n",
        "    generator = models.generator\n",
        "    discriminator = models.discriminator\n",
        "\n",
        "    ''' graph '''\n",
        "    # inputs\n",
        "    z = tf.placeholder(tf.float32, shape=[None, z_dim])\n",
        "\n",
        "    # generate\n",
        "    fake = generator(z, training=False ,reuse=False)\n",
        "    f_logit = discriminator(fake,training=False ,reuse=False)\n",
        "\n",
        "\n",
        "\"\"\" train \"\"\"\n",
        "''' init '''\n",
        "# session\n",
        "sess = utils.session()\n",
        "# saver\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "''' initialization '''\n",
        "ckpt_dir = '/content/drive/My Drive/GP/checkpoints/celeba_dcgan/Epoch_(5)_(2175of3165).ckpt'\n",
        "saver.restore(sess, ckpt_dir)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "saver.restore(sess, ckpt_dir)\n",
        "\n",
        "try:\n",
        "    \n",
        "    cnt = 0\n",
        "    while(True):\n",
        "        if(cnt >= 50):\n",
        "          break\n",
        "        z_ipt = np.random.normal(size=[batch_size, z_dim])\n",
        "        img = sess.run(fake, feed_dict={z: z_ipt})\n",
        "        prob = sess.run(f_logit,{z: z_ipt})\n",
        "        loss = tf.reduce_mean(prob)\n",
        "        l = sess.run(loss)\n",
        "        print(l)\n",
        "        save_dir = '/content/drive/My Drive/results_dcgan/test'\n",
        "        utils.mkdir(save_dir + '/')\n",
        "        cnt = batchimwrite(img, '%s/img' % (save_dir), cnt, prob)\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    traceback.print_exc()\n",
        "finally:\n",
        "    print(\" [*] Close main session!\")\n",
        "    sess.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/GP/checkpoints/celeba_dcgan/Epoch_(5)_(2175of3165).ckpt\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/GP/checkpoints/celeba_dcgan/Epoch_(5)_(2175of3165).ckpt\n",
            "-3.0695233\n",
            "1 [-2.963564]\n",
            "2 [-2.4600554]\n",
            "3 [-1.850536]\n",
            "4 [-2.5242686]\n",
            "5 [-3.701902]\n",
            "6 [-2.6039734]\n",
            "7 [-2.862306]\n",
            "8 [-2.517914]\n",
            "9 [-2.6923482]\n",
            "10 [-0.9518598]\n",
            "11 [-3.3290508]\n",
            "12 [-3.0636315]\n",
            "13 [-3.1607516]\n",
            "14 [-3.7339392]\n",
            "15 [-2.7652266]\n",
            "16 [-2.5166419]\n",
            "17 [-2.9956656]\n",
            "18 [-2.9109795]\n",
            "19 [-4.334607]\n",
            "20 [-3.218203]\n",
            "21 [-2.3239996]\n",
            "22 [-3.643551]\n",
            "23 [-3.3223248]\n",
            "24 [-3.1568365]\n",
            "25 [-1.2529931]\n",
            "26 [-3.218162]\n",
            "27 [-2.9451156]\n",
            "28 [-3.5184782]\n",
            "29 [-1.2141782]\n",
            "30 [-3.5605958]\n",
            "31 [-3.2917185]\n",
            "32 [-4.431612]\n",
            "33 [-1.5870966]\n",
            "34 [-3.3159237]\n",
            "35 [-2.3520682]\n",
            "36 [-1.1997216]\n",
            "37 [-2.6637683]\n",
            "38 [-2.660379]\n",
            "39 [0.00089039]\n",
            "40 [-2.1964862]\n",
            "41 [-2.7465408]\n",
            "42 [-2.3536758]\n",
            "43 [-2.6455069]\n",
            "44 [-1.1448296]\n",
            "45 [-1.9529983]\n",
            "46 [-2.9788349]\n",
            "47 [-4.3652334]\n",
            "48 [-3.3849907]\n",
            "49 [-2.9320104]\n",
            "50 [-3.4349647]\n",
            " [*] Close main session!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juEzXgTcwzEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r '/content/drive/My Drive/results/images7.zip' '/content/drive/My Drive/results/celeba_dcgan7'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpX3l0e7J_op",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak4Id6OsJ_wM",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}